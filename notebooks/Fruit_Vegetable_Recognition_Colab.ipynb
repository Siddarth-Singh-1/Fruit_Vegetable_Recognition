{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üççüçÖ Fruit & Vegetable Recognition using MobileNet\n",
    "\n",
    "This notebook trains a deep learning model to classify 36 different types of fruits and vegetables using MobileNetV2 transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow keras pillow numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset"
   },
   "source": [
    "## 3. Download and Setup Dataset\n",
    "\n",
    "**Choose ONE of these options:**\n",
    "\n",
    "**Option 1: Load from Google Drive (Recommended if already uploaded)**\n",
    "- If you have `archive.zip` in your Google Drive at `DATA/archive.zip`\n",
    "- This is the fastest option!\n",
    "\n",
    "**Option 2: Using Kaggle API**\n",
    "- Upload your kaggle.json file\n",
    "- Dataset downloads automatically\n",
    "\n",
    "**Option 3: Manual Upload**\n",
    "- Upload the dataset zip file directly to Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaggle_setup"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# OPTION 1: Load from Google Drive (RECOMMENDED)\n",
    "# ============================================\n",
    "# Uncomment the lines below if you have archive.zip in Google Drive\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Extract dataset from Google Drive\n",
    "!unzip -q /content/drive/MyDrive/DATA/archive.zip -d dataset\n",
    "print(\"‚úÖ Dataset extracted from Google Drive!\")\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: Using Kaggle API\n",
    "# ============================================\n",
    "# Uncomment the lines below if using Kaggle API\n",
    "\n",
    "# from google.colab import files\n",
    "# files.upload()  # Upload your kaggle.json\n",
    "\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d kritikseth/fruit-and-vegetable-image-recognition\n",
    "# !unzip -q fruit-and-vegetable-image-recognition.zip -d dataset\n",
    "# print(\"‚úÖ Dataset downloaded from Kaggle!\")\n",
    "\n",
    "# ============================================\n",
    "# OPTION 3: Manual Upload\n",
    "# ============================================\n",
    "# Uncomment the lines below to upload manually\n",
    "\n",
    "# from google.colab import files\n",
    "# print(\"Upload your dataset zip file:\")\n",
    "# uploaded = files.upload()\n",
    "# import zipfile\n",
    "# for filename in uploaded.keys():\n",
    "#     with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('dataset')\n",
    "# print(\"‚úÖ Dataset uploaded and extracted!\")\n",
    "\n",
    "# ============================================\n",
    "# Set dataset paths\n",
    "# ============================================\n",
    "DATASET_DIR = 'dataset'\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATASET_DIR, 'validation')\n",
    "\n",
    "print(f\"\\nüìÅ Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"üìÅ Training directory: {TRAIN_DIR}\")\n",
    "print(f\"üìÅ Validation directory: {VAL_DIR}\")\n",
    "\n",
    "# Verify dataset structure\n",
    "if os.path.exists(TRAIN_DIR) and os.path.exists(VAL_DIR):\n",
    "    train_classes = len(os.listdir(TRAIN_DIR))\n",
    "    val_classes = len(os.listdir(VAL_DIR))\n",
    "    print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"   Training classes: {train_classes}\")\n",
    "    print(f\"   Validation classes: {val_classes}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Warning: Dataset directories not found!\")\n",
    "    print(\"   Please check the paths and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 4. Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "params"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Class labels\n",
    "labels = {\n",
    "    0: 'apple', 1: 'banana', 2: 'beetroot', 3: 'bell pepper', 4: 'cabbage', \n",
    "    5: 'capsicum', 6: 'carrot', 7: 'cauliflower', 8: 'chilli pepper', 9: 'corn', \n",
    "    10: 'cucumber', 11: 'eggplant', 12: 'garlic', 13: 'ginger', 14: 'grapes', \n",
    "    15: 'jalepeno', 16: 'kiwi', 17: 'lemon', 18: 'lettuce', 19: 'mango', \n",
    "    20: 'onion', 21: 'orange', 22: 'paprika', 23: 'pear', 24: 'peas', \n",
    "    25: 'pineapple', 26: 'pomegranate', 27: 'potato', 28: 'raddish', \n",
    "    29: 'soy beans', 30: 'spinach', 31: 'sweetcorn', 32: 'sweetpotato', \n",
    "    33: 'tomato', 34: 'turnip', 35: 'watermelon'\n",
    "}\n",
    "\n",
    "NUM_CLASSES = len(labels)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep"
   },
   "source": [
    "## 5. Data Preparation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_gen"
   },
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Classes found: {len(train_generator.class_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## 6. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz_samples"
   },
   "outputs": [],
   "source": [
    "# Display sample images from training set\n",
    "sample_images, sample_labels = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(min(9, len(sample_images))):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    class_idx = np.argmax(sample_labels[i])\n",
    "    plt.title(f\"Class: {labels[class_idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model"
   },
   "source": [
    "## 7. Build Model using MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "build_model"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2 without top layers\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "callbacks"
   },
   "source": [
    "## 8. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_callbacks"
   },
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save('FV.h5')\n",
    "print(\"Model saved as FV.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plot"
   },
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_history"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(history.history['loss'], label='Train Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## 11. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eval_model"
   },
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predict"
   },
   "source": [
    "## 12. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_func"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def predict_image(image_path, model):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        model: Trained Keras model\n",
    "    \n",
    "    Returns:\n",
    "        Predicted class name and confidence\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    # Get class name\n",
    "    class_name = labels[predicted_class]\n",
    "    \n",
    "    # Display image with prediction\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predicted: {class_name.capitalize()}\\nConfidence: {confidence*100:.2f}%\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return class_name, confidence\n",
    "\n",
    "# Example usage (uncomment and provide image path)\n",
    "# predicted_class, confidence = predict_image('path/to/your/image.jpg', model)\n",
    "# print(f\"Predicted: {predicted_class} with {confidence*100:.2f}% confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## 13. Test with Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_samples"
   },
   "outputs": [],
   "source": [
    "# Test with random validation images\n",
    "val_generator.reset()\n",
    "test_images, test_labels = next(val_generator)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images[:9])\n",
    "\n",
    "# Display results\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(test_images[i])\n",
    "    \n",
    "    true_class = np.argmax(test_labels[i])\n",
    "    pred_class = np.argmax(predictions[i])\n",
    "    confidence = predictions[i][pred_class]\n",
    "    \n",
    "    color = 'green' if true_class == pred_class else 'red'\n",
    "    plt.title(f\"True: {labels[true_class]}\\nPred: {labels[pred_class]}\\n({confidence*100:.1f}%)\", \n",
    "              color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 14. Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_model"
   },
   "outputs": [],
   "source": [
    "# Download the model file (for Colab)\n",
    "from google.colab import files\n",
    "\n",
    "try:\n",
    "    files.download('FV.h5')\n",
    "    print(\"Model downloaded successfully!\")\n",
    "except:\n",
    "    print(\"Not running in Colab or download failed. Model saved locally as FV.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_test"
   },
   "source": [
    "## 15. Interactive Web UI in Colab (Gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_predict"
   },
   "outputs": [],
   "source": [
    "# Install Gradio for interactive web UI\n",
    "!pip install -q gradio\n",
    "\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "def predict_fruit_vegetable(image):\n",
    "    \"\"\"\n",
    "    Predict fruit/vegetable from uploaded image\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image or numpy array\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with prediction results\n",
    "    \"\"\"\n",
    "    # Ensure image is PIL Image\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.fromarray(image)\n",
    "    \n",
    "    # Resize and preprocess\n",
    "    img = image.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    # Get class name\n",
    "    class_name = labels[predicted_class].capitalize()\n",
    "    \n",
    "    # Determine category\n",
    "    fruits = ['Apple', 'Banana', 'Bell Pepper', 'Chilli Pepper', 'Grapes', 'Jalepeno', \n",
    "              'Kiwi', 'Lemon', 'Mango', 'Orange', 'Paprika', 'Pear', 'Pineapple', \n",
    "              'Pomegranate', 'Watermelon']\n",
    "    \n",
    "    category = \"üçé Fruit\" if class_name in fruits else \"ü•¨ Vegetable\"\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_3_idx = np.argsort(predictions[0])[-3:][::-1]\n",
    "    top_3_results = {\n",
    "        labels[idx].capitalize(): float(predictions[0][idx]) \n",
    "        for idx in top_3_idx\n",
    "    }\n",
    "    \n",
    "    # Format result\n",
    "    result = f\"\"\"\n",
    "    ### Prediction: {class_name}\n",
    "    **Category:** {category}\n",
    "    **Confidence:** {confidence*100:.2f}%\n",
    "    \n",
    "    #### Top 3 Predictions:\n",
    "    \"\"\"\n",
    "    for name, conf in top_3_results.items():\n",
    "        result += f\"\\n- **{name}**: {conf*100:.2f}%\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict_fruit_vegetable,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Fruit or Vegetable Image\"),\n",
    "    outputs=gr.Markdown(label=\"Prediction Results\"),\n",
    "    title=\"üççüçÖ Fruit & Vegetable Classifier\",\n",
    "    description=\"Upload an image of a fruit or vegetable to classify it! Supports 36 different classes.\",\n",
    "    examples=[],  # You can add example image paths here\n",
    "    theme=\"soft\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "print(\"üöÄ Launching interactive web UI...\")\n",
    "print(\"üì± The interface will open below and provide a public URL you can share!\")\n",
    "demo.launch(share=True, debug=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fruit_Vegetable_Recognition_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
